{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ibmTest.py\n",
    "# \n",
    "# This file tests all 11 classifiers using the NLClassifier IBM Service\n",
    "# previously created using ibmTrain.py\n",
    "# \n",
    "# TODO: You must fill out all of the functions in this file following \n",
    "# \t\tthe specifications exactly. DO NOT modify the headers of any\n",
    "#\t\tfunctions. Doing so will cause your program to fail the autotester.\n",
    "#\n",
    "#\t\tYou may use whatever libraries you like (as long as they are available\n",
    "#\t\ton CDF). You may find json, request, or pycurl helpful.\n",
    "#\t\tYou may also find it helpful to reuse some of your functions from ibmTrain.py.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classifier_ids(username, password):\n",
    "    # Retrieves a list of classifier ids from a NLClassifier service \n",
    "    # an outputfile named ibmTrain#.csv (where # is n_lines_to_extract).\n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\t\t\n",
    "    # Returns:\n",
    "    #\ta list of classifier ids as strings\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classifiers call fails for any reason\n",
    "    #\n",
    "\n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers\"\n",
    "\n",
    "    response = requests.get(url, data={}, auth=(username, password))\n",
    "    \n",
    "    if not response.ok:\n",
    "        raise Exception(\"Classifier call failed.\")\n",
    "        \n",
    "    id_list = []\n",
    "    for classifier in response.json()['classifiers']:\n",
    "        id_list.append(classifier['classifier_id'])\n",
    "        \n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'c7fa4ax22-nlc-1269', u'c7fa4ax22-nlc-1270', u'c7fa49x23-nlc-1182']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classifier_ids(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assert_all_classifiers_are_available(username, password, classifier_id_list):\n",
    "    # Asserts all classifiers in the classifier_id_list are 'Available' \n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\tclassifier_id_list - a list of classifier ids as strings\n",
    "    #\t\t\n",
    "    # Returns:\n",
    "    #\tNone\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classifiers call fails for any reason AND \n",
    "    #\tIt should throw an error if any classifier is NOT 'Available'\n",
    "    #\n",
    "    \n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/\"\n",
    "\n",
    "    for c_id in classifier_id_list:\n",
    "        response = requests.get(url + c_id, data={}, auth=(username, password))\n",
    "        if not response.ok:\n",
    "            raise Exception(\"Classifier call failed.\")\n",
    "        if response.json()['status'] != \"Available\":\n",
    "            # The term \"throwing an error\" is undefined in python,\n",
    "            # so we will print a message and then raise an exception\n",
    "            raise Exception(\"Classifier {} is not ready\".format(c_id))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Classifier c7fa4ax22-nlc-1269 is not ready",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-19c2ce5d1fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massert_all_classifiers_are_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_classifier_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-aaede1650c53>\u001b[0m in \u001b[0;36massert_all_classifiers_are_available\u001b[0;34m(username, password, classifier_id_list)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# The term \"throwing an error\" is undefined in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# so we will print a message and then raise an exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifier {} is not ready\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Classifier c7fa4ax22-nlc-1269 is not ready"
     ]
    }
   ],
   "source": [
    "assert_all_classifiers_are_available(username, password, get_classifier_ids(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_single_text(username, password, classifier_id, text):\n",
    "    # Classifies a given text using a single classifier from an NLClassifier \n",
    "    # service\n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\tclassifier_id - a classifier id, as a string\n",
    "    #\t\t\n",
    "    #\ttext - a string of text to be classified, not UTF-8 encoded\n",
    "    #\t\tex. \"Oh, look a tweet!\"\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tA \"classification\". Aka: \n",
    "    #\ta dictionary containing the top_class and the confidences of all the possible classes \n",
    "    #\tFormat example:\n",
    "    #\t\t{'top_class': 'class_name',\n",
    "    #\t\t 'classes': [\n",
    "    #\t\t\t\t\t  {'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t  {'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t]\n",
    "    #\t\t}\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classify call fails for any reason \n",
    "    #\n",
    "\n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/\"\n",
    "    text = urllib.quote(text.encode('utf8'))\n",
    "    url = url + classifier_id + \"/classify?text=\" + text\n",
    "    \n",
    "    response = requests.get(url, data={}, auth=(username, password))\n",
    "    if not response.ok:\n",
    "        raise Exception(\"Classifier call failed.\")\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_all_texts(username, password, input_csv_name):\n",
    "        # Classifies all texts in an input csv file using all classifiers for a given NLClassifier\n",
    "        # service.\n",
    "        #\n",
    "        # Inputs:\n",
    "        #       username - username for the NLClassifier to be used, as a string\n",
    "        #\n",
    "        #       password - password for the NLClassifier to be used, as a string\n",
    "        #      \n",
    "        #       input_csv_name - full path and name of an input csv file in the \n",
    "        #              6 column format of the input test/training files\n",
    "        #\n",
    "        # Returns:\n",
    "        #       A dictionary of lists of \"classifications\".\n",
    "        #       Each dictionary key is the name of a classifier.\n",
    "        #       Each dictionary value is a list of \"classifications\" where a\n",
    "        #       \"classification\" is in the same format as returned by\n",
    "        #       classify_single_text.\n",
    "        #       Each element in the main dictionary is:\n",
    "        #       A list of dictionaries, one for each text, in order of lines in the\n",
    "        #       input file. Each element is a dictionary containing the top_class\n",
    "        #       and the confidences of all the possible classes (ie the same\n",
    "        #       format as returned by classify_single_text)\n",
    "        #       Format example:\n",
    "        #              {‘classifiername’:\n",
    "        #                      [\n",
    "        #                              {'top_class': 'class_name',\n",
    "        #                              'classes': [\n",
    "        #                                        {'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "        #                                         {'class_name': 'myclass2', 'confidence': 0.001}\n",
    "        #                                          ]\n",
    "        #                              },\n",
    "        #                              {'top_class': 'class_name',\n",
    "        #                              ...\n",
    "        #                              }\n",
    "        #                      ]\n",
    "        #              , ‘classifiername2’:\n",
    "        #                      [\n",
    "        #                      …      \n",
    "        #                      ]\n",
    "        #              …\n",
    "        #              }\n",
    "        #\n",
    "        # Error Handling:\n",
    "        #       This function should throw an exception if the classify call fails for any reason\n",
    "        #       or if the input csv file is of an improper format.\n",
    "        #\n",
    "        \n",
    "        return_dict = {}\n",
    "        \n",
    "        id_list = get_classifier_ids(username, password)\n",
    "        for c_id in id_list:\n",
    "            return_dict[c_id] = []\n",
    "        \n",
    "        with open(input_csv_name, \"r\") as _input:\n",
    "                reader = csv.reader(_input)\n",
    "                for row in itertools.islice(reader, 0, None):\n",
    "                    tweet = row[5].strip()\n",
    "                    t_class = int(row[0])\n",
    "                    \n",
    "                    for c_id in id_list:\n",
    "                        return_dict[c_id].append(classify_single_text(username, password, c_id, tweet))\n",
    "        \n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_of_single_classifier(classifier_dict, input_csv_file_name):\n",
    "    # Given a list of \"classifications\" for a given classifier, compute the accuracy of this\n",
    "    # classifier according to the input csv file\n",
    "    #\n",
    "    # Inputs:\n",
    "    # \tclassifier_dict - A list of \"classifications\". Aka:\n",
    "    #\t\tA list of dictionaries, one for each text, in order of lines in the \n",
    "    #\t\tinput file. Each element is a dictionary containing the top_class\n",
    "    #\t\tand the confidences of all the possible classes (ie the same\n",
    "    #\t\tformat as returned by classify_single_text) \t\n",
    "    # \t\tFormat example:\n",
    "    #\t\t\t[\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t \t 'classes': [\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t\t\t]\n",
    "    #\t\t\t\t},\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t\t...\n",
    "    #\t\t\t\t}\n",
    "    #\t\t\t]\n",
    "    #\n",
    "    #\tinput_csv_name - full path and name of an input csv file in the  \n",
    "    #\t\t6 column format of the input test/training files\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tThe accuracy of the classifier, as a fraction between [0.0-1.0] (ie percentage/100). \\\n",
    "    #\tSee the handout for more info.\n",
    "    #\n",
    "    # Error Handling:\n",
    "    # \tThis function should throw an error if there is an issue with the \n",
    "    #\tinputs.\n",
    "    #\n",
    "\n",
    "    num_correct = 0\n",
    "    \n",
    "    with open(input_csv_file_name, \"r\") as _input:\n",
    "            reader = csv.reader(_input)\n",
    "            for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "                tweet_class = int(row[0])\n",
    "\n",
    "                top_class = int(classifier_dict[i]['top_class'])\n",
    "                num_correct += (tweet_class == top_class)\n",
    "                \n",
    "    return num_correct / float(len(classifier_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brad = {\n",
    "  \"classifier_id\": \"10D41B-nlc-1\",\n",
    "  \"url\": \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/10D41B-nlc-1/classify?text=How%20hot%20wil/10D41B-nlc-1\",\n",
    "  \"text\": \"How hot will it be today?\",\n",
    "  \"top_class\": \"temperature\",\n",
    "  \"classes\": [\n",
    "    {\n",
    "      \"class_name\": \"temperature\",\n",
    "      \"confidence\": 0.9998201258549781\n",
    "    },\n",
    "    {\n",
    "      \"class_name\": \"conditions\",\n",
    "      \"confidence\": 0.00017987414502176904\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017987414502176904"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_list = classifier_dict[i]['classes']\n",
    "index = next(index for (index, d) in enumerate(conf_list) if d[\"class_name\"] == top_class)\n",
    "conf_list[index][\"confidence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brad[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_average_confidence_of_single_classifier(classifier_dict, input_csv_file_name):\n",
    "    # Given a list of \"classifications\" for a given classifier, compute the average \n",
    "    # confidence of this classifier wrt the selected class, according to the input\n",
    "    # csv file. \n",
    "    #\n",
    "    # Inputs:\n",
    "    # \tclassifier_dict - A list of \"classifications\". Aka:\n",
    "    #\t\tA list of dictionaries, one for each text, in order of lines in the \n",
    "    #\t\tinput file. Each element is a dictionary containing the top_class\n",
    "    #\t\tand the confidences of all the possible classes (ie the same\n",
    "    #\t\tformat as returned by classify_single_text) \t\n",
    "    # \t\tFormat example:\n",
    "    #\t\t\t[\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t \t 'classes': [\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t\t\t]\n",
    "    #\t\t\t\t},\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t\t...\n",
    "    #\t\t\t\t}\n",
    "    #\t\t\t]\n",
    "    #\n",
    "    #\tinput_csv_name - full path and name of an input csv file in the  \n",
    "    #\t\t6 column format of the input test/training files\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tThe average confidence of the classifier, as a number between [0.0-1.0]\n",
    "    #\tSee the handout for more info.\n",
    "    #\n",
    "    # Error Handling:\n",
    "    # \tThis function should throw an error if there is an issue with the \n",
    "    #\tinputs.\n",
    "    #\n",
    "\n",
    "    # Sums for classes [zero, four]\n",
    "    confidence_sums = [0, 0]\n",
    "    \n",
    "    with open(input_csv_name, \"r\") as _input:\n",
    "            reader = csv.reader(_input)\n",
    "            for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "                tweet_class = int(row[0])\n",
    "                \n",
    "                top_class = classifier_dict[i][\"top_class\"]\n",
    "                conf_list = classifier_dict[i][\"classes\"]\n",
    "                \n",
    "                selected_index = next(index for (index, d) in enumerate(conf_list) if d[\"class_name\"] == top_class)\n",
    "                confidence_sums[tweet_class / 4] += conf_list[selected_index][\"confidence\"]\n",
    "    \n",
    "    confidence_sums[0] /= float(len(classifier_dict))\n",
    "    confidence_sums[1] /= float(len(classifier_dict))\n",
    "    \n",
    "    return confidence_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_test_data = 'datasets/testdata.manualSUBSET.2009.06.14.csv'\n",
    "username = \"2bd0e6c7-5784-4967-860c-a9778754fdee\"\n",
    "password = \"rFs4Solusscl\"\n",
    "\n",
    "#STEP 1: Ensure all classifiers are ready for testing\n",
    "try:\n",
    "    assert_all_classifiers_are_available(username, password, get_classifier_ids(username, password))\n",
    "except Exception as e:\n",
    "    print \"Error({0}): {1}\".format(e.errno, e.strerror)\n",
    "    \n",
    "#STEP 2: Test the test data on all classifiers\n",
    "classd_dict = classify_all_texts(username, password, input_test_data):\n",
    "\n",
    "#STEP 3: Compute the accuracy for each classifier\n",
    "#STEP 4: Compute the confidence of each class for each classifier\n",
    "\n",
    "per_classifier_acc = []\n",
    "per_classifier_confidence = [] # pairs per classifier (one for each class)\n",
    "for c_id in get_classifier_ids(username, password):\n",
    "    per_classifier_list = classd_dict[c_id]\n",
    "    \n",
    "    acc = compute_accuracy_of_single_classifier(per_classifier_list, input_test_data)\n",
    "    per_classifier_acc.append(acc)\n",
    "    \n",
    "    conf = compute_average_confidence_of_single_classifier(per_classifier_list, input_test_data)\n",
    "    per_classifier_confidence.append(conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
