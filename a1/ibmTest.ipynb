{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ibmTest.py\n",
    "# \n",
    "# This file tests all 11 classifiers using the NLClassifier IBM Service\n",
    "# previously created using ibmTrain.py\n",
    "# \n",
    "# TODO: You must fill out all of the functions in this file following \n",
    "# \t\tthe specifications exactly. DO NOT modify the headers of any\n",
    "#\t\tfunctions. Doing so will cause your program to fail the autotester.\n",
    "#\n",
    "#\t\tYou may use whatever libraries you like (as long as they are available\n",
    "#\t\ton CDF). You may find json, request, or pycurl helpful.\n",
    "#\t\tYou may also find it helpful to reuse some of your functions from ibmTrain.py.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classifier_ids(username, password):\n",
    "    # Retrieves a list of classifier ids from a NLClassifier service \n",
    "    # an outputfile named ibmTrain#.csv (where # is n_lines_to_extract).\n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\t\t\n",
    "    # Returns:\n",
    "    #\ta list of classifier ids as strings\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classifiers call fails for any reason\n",
    "    #\n",
    "\n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers\"\n",
    "\n",
    "    response = requests.get(url, data={}, auth=(username, password))\n",
    "    \n",
    "    if not response.ok:\n",
    "        raise Exception(\"Classifier call failed.\")\n",
    "        \n",
    "    id_list = []\n",
    "    for classifier in response.json()['classifiers']:\n",
    "        id_list.append(classifier['classifier_id'])\n",
    "        \n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'c7fa4ax22-nlc-1269', u'c7fa4ax22-nlc-1270', u'c7fa49x23-nlc-1182']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classifier_ids(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assert_all_classifiers_are_available(username, password, classifier_id_list):\n",
    "    # Asserts all classifiers in the classifier_id_list are 'Available' \n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\tclassifier_id_list - a list of classifier ids as strings\n",
    "    #\t\t\n",
    "    # Returns:\n",
    "    #\tNone\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classifiers call fails for any reason AND \n",
    "    #\tIt should throw an error if any classifier is NOT 'Available'\n",
    "    #\n",
    "    \n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/\"\n",
    "\n",
    "    for c_id in classifier_id_list:\n",
    "        response = requests.get(url + c_id, data={}, auth=(username, password))\n",
    "        if not response.ok:\n",
    "            raise Exception(\"Classifier call failed.\")\n",
    "        if response.json()['status'] != \"Available\":\n",
    "            # The term \"throwing an error\" is undefined in python,\n",
    "            # so we will print a message and then raise an exception\n",
    "            raise Exception(\"Classifier {} is {}, not Available\".format(c_id, response.json()['status']))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_all_classifiers_are_available(username, password, get_classifier_ids(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_single_text(username, password, classifier_id, text):\n",
    "    # Classifies a given text using a single classifier from an NLClassifier \n",
    "    # service\n",
    "    #\n",
    "    # Inputs: \n",
    "    # \tusername - username for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    # \tpassword - password for the NLClassifier to be used, as a string\n",
    "    #\n",
    "    #\tclassifier_id - a classifier id, as a string\n",
    "    #\t\t\n",
    "    #\ttext - a string of text to be classified, not UTF-8 encoded\n",
    "    #\t\tex. \"Oh, look a tweet!\"\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tA \"classification\". Aka: \n",
    "    #\ta dictionary containing the top_class and the confidences of all the possible classes \n",
    "    #\tFormat example:\n",
    "    #\t\t{'top_class': 'class_name',\n",
    "    #\t\t 'classes': [\n",
    "    #\t\t\t\t\t  {'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t  {'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t]\n",
    "    #\t\t}\n",
    "    #\n",
    "    # Error Handling:\n",
    "    #\tThis function should throw an exception if the classify call fails for any reason \n",
    "    #\n",
    "\n",
    "    url = \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/\"\n",
    "    text = urllib.quote(text.encode('utf8'))\n",
    "    url = url + classifier_id + \"/classify?text=\" + text\n",
    "    \n",
    "    response = requests.get(url, data={}, auth=(username, password))\n",
    "    if not response.ok:\n",
    "        raise Exception(\"Classifier call failed.\")\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @dittebb pulled a muscle in the shoulder. I sure hope it gets better soon.,0\n",
    "resp = classify_single_text(username, password, \"c7fa4ax22-nlc-1270\", \"@dittebb pulled a muscle in the shoulder. I sure hope it gets better soon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'classes': [{u'class_name': u'0', u'confidence': 0.995990028092351},\n",
       "  {u'class_name': u'4', u'confidence': 0.004009971907648813}],\n",
       " u'classifier_id': u'c7fa4ax22-nlc-1270',\n",
       " u'text': u'@dittebb pulled a muscle in the shoulder. I sure hope it gets better soon.',\n",
       " u'top_class': u'0',\n",
       " u'url': u'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/c7fa4ax22-nlc-1270'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_all_texts(username, password, input_csv_name):\n",
    "        # Classifies all texts in an input csv file using all classifiers for a given NLClassifier\n",
    "        # service.\n",
    "        #\n",
    "        # Inputs:\n",
    "        #       username - username for the NLClassifier to be used, as a string\n",
    "        #\n",
    "        #       password - password for the NLClassifier to be used, as a string\n",
    "        #      \n",
    "        #       input_csv_name - full path and name of an input csv file in the \n",
    "        #              6 column format of the input test/training files\n",
    "        #\n",
    "        # Returns:\n",
    "        #       A dictionary of lists of \"classifications\".\n",
    "        #       Each dictionary key is the name of a classifier.\n",
    "        #       Each dictionary value is a list of \"classifications\" where a\n",
    "        #       \"classification\" is in the same format as returned by\n",
    "        #       classify_single_text.\n",
    "        #       Each element in the main dictionary is:\n",
    "        #       A list of dictionaries, one for each text, in order of lines in the\n",
    "        #       input file. Each element is a dictionary containing the top_class\n",
    "        #       and the confidences of all the possible classes (ie the same\n",
    "        #       format as returned by classify_single_text)\n",
    "        #       Format example:\n",
    "        #              {‘classifiername’:\n",
    "        #                      [\n",
    "        #                              {'top_class': 'class_name',\n",
    "        #                              'classes': [\n",
    "        #                                        {'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "        #                                         {'class_name': 'myclass2', 'confidence': 0.001}\n",
    "        #                                          ]\n",
    "        #                              },\n",
    "        #                              {'top_class': 'class_name',\n",
    "        #                              ...\n",
    "        #                              }\n",
    "        #                      ]\n",
    "        #              , ‘classifiername2’:\n",
    "        #                      [\n",
    "        #                      …      \n",
    "        #                      ]\n",
    "        #              …\n",
    "        #              }\n",
    "        #\n",
    "        # Error Handling:\n",
    "        #       This function should throw an exception if the classify call fails for any reason\n",
    "        #       or if the input csv file is of an improper format.\n",
    "        #\n",
    "        \n",
    "        return_dict = {}\n",
    "        \n",
    "        id_list = get_classifier_ids(username, password)\n",
    "        for c_id in id_list:\n",
    "            return_dict[c_id] = []\n",
    "        \n",
    "        with open(input_csv_name, \"r\") as _input:\n",
    "                reader = csv.reader(_input)\n",
    "                for row in itertools.islice(reader, 0, None):\n",
    "                    tweet = row[5].strip()\n",
    "                    t_class = int(row[0])\n",
    "                    \n",
    "                    for c_id in id_list:\n",
    "                        return_dict[c_id].append(classify_single_text(username, password, c_id, tweet))\n",
    "        \n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_of_single_classifier(classifier_dict, input_csv_file_name):\n",
    "    # Given a list of \"classifications\" for a given classifier, compute the accuracy of this\n",
    "    # classifier according to the input csv file\n",
    "    #\n",
    "    # Inputs:\n",
    "    # \tclassifier_dict - A list of \"classifications\". Aka:\n",
    "    #\t\tA list of dictionaries, one for each text, in order of lines in the \n",
    "    #\t\tinput file. Each element is a dictionary containing the top_class\n",
    "    #\t\tand the confidences of all the possible classes (ie the same\n",
    "    #\t\tformat as returned by classify_single_text) \t\n",
    "    # \t\tFormat example:\n",
    "    #\t\t\t[\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t \t 'classes': [\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t\t\t]\n",
    "    #\t\t\t\t},\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t\t...\n",
    "    #\t\t\t\t}\n",
    "    #\t\t\t]\n",
    "    #\n",
    "    #\tinput_csv_name - full path and name of an input csv file in the  \n",
    "    #\t\t6 column format of the input test/training files\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tThe accuracy of the classifier, as a fraction between [0.0-1.0] (ie percentage/100). \\\n",
    "    #\tSee the handout for more info.\n",
    "    #\n",
    "    # Error Handling:\n",
    "    # \tThis function should throw an error if there is an issue with the \n",
    "    #\tinputs.\n",
    "    #\n",
    "\n",
    "    num_correct = 0\n",
    "    \n",
    "    with open(input_csv_file_name, \"r\") as _input:\n",
    "            reader = csv.reader(_input)\n",
    "            for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "                tweet_class = int(row[0])\n",
    "\n",
    "                top_class = int(classifier_dict[i]['top_class'])\n",
    "                num_correct += (tweet_class == top_class)\n",
    "                \n",
    "    return num_correct / float(len(classifier_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_average_confidence_of_single_classifier(classifier_dict, input_csv_file_name):\n",
    "    # Given a list of \"classifications\" for a given classifier, compute the average \n",
    "    # confidence of this classifier wrt the selected class, according to the input\n",
    "    # csv file. \n",
    "    #\n",
    "    # Inputs:\n",
    "    # \tclassifier_dict - A list of \"classifications\". Aka:\n",
    "    #\t\tA list of dictionaries, one for each text, in order of lines in the \n",
    "    #\t\tinput file. Each element is a dictionary containing the top_class\n",
    "    #\t\tand the confidences of all the possible classes (ie the same\n",
    "    #\t\tformat as returned by classify_single_text) \t\n",
    "    # \t\tFormat example:\n",
    "    #\t\t\t[\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t \t 'classes': [\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass', 'confidence': 0.999} ,\n",
    "    #\t\t\t\t\t\t  \t{'class_name': 'myclass2', 'confidence': 0.001}\n",
    "    #\t\t\t\t\t\t\t]\n",
    "    #\t\t\t\t},\n",
    "    #\t\t\t\t{'top_class': 'class_name',\n",
    "    #\t\t\t\t...\n",
    "    #\t\t\t\t}\n",
    "    #\t\t\t]\n",
    "    #\n",
    "    #\tinput_csv_name - full path and name of an input csv file in the  \n",
    "    #\t\t6 column format of the input test/training files\n",
    "    #\n",
    "    # Returns:\n",
    "    #\tThe average confidence of the classifier, as a number between [0.0-1.0]\n",
    "    #\tSee the handout for more info.\n",
    "    #\n",
    "    # Error Handling:\n",
    "    # \tThis function should throw an error if there is an issue with the \n",
    "    #\tinputs.\n",
    "    #\n",
    "\n",
    "    # Sums for [incorrect, correct] guesses\n",
    "    confidence_sums = [0, 0]\n",
    "    # Number of [incorrect, correct] guesses\n",
    "    total_number_seen = [0, 0]\n",
    "    \n",
    "    with open(input_csv_file_name, \"r\") as _input:\n",
    "            reader = csv.reader(_input)\n",
    "            for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "                tweet_class = int(row[0])\n",
    "                \n",
    "                most_conf_class = classifier_dict[i][\"classes\"][0]\n",
    "                is_classification_correct = int(most_conf_class[\"class_name\"]) == tweet_class\n",
    "                \n",
    "                confidence_sums[is_classification_correct] += most_conf_class[\"confidence\"]\n",
    "                total_number_seen[is_classification_correct] += 1\n",
    "    \n",
    "    confidence_sums[0] /= float(total_number_seen[0])\n",
    "    confidence_sums[1] /= float(total_number_seen[1])\n",
    "    \n",
    "    return confidence_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_test_data = 'datasets/testdata.manualSUBSET.2009.06.14.csv'\n",
    "username = \"2bd0e6c7-5784-4967-860c-a9778754fdee\"\n",
    "password = \"rFs4Solusscl\"\n",
    "\n",
    "#STEP 1: Ensure all classifiers are ready for testing\n",
    "try:\n",
    "    assert_all_classifiers_are_available(username, password, get_classifier_ids(username, password))\n",
    "except Exception as e:\n",
    "    print \"Error: {}\".format(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STEP 2: Test the test data on all classifiers\n",
    "try:\n",
    "    classd_dict = classify_all_texts(username, password, input_test_data)\n",
    "except Exception as e:\n",
    "    print \"Error: {}\".format(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'classes': [{u'class_name': u'0', u'confidence': 0.9918643770825553},\n",
       "  {u'class_name': u'4', u'confidence': 0.008135622917444761}],\n",
       " u'classifier_id': u'c7fa49x23-nlc-1182',\n",
       " u'text': u'@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
       " u'top_class': u'0',\n",
       " u'url': u'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/c7fa49x23-nlc-1182'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 500\n",
    "classd_dict['c7fa49x23-nlc-1182'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'classes': [{u'class_name': u'0', u'confidence': 0.5941090107927917},\n",
       "  {u'class_name': u'4', u'confidence': 0.4058909892072084}],\n",
       " u'classifier_id': u'c7fa4ax22-nlc-1269',\n",
       " u'text': u'@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
       " u'top_class': u'0',\n",
       " u'url': u'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/c7fa4ax22-nlc-1269'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2500\n",
    "classd_dict[\"c7fa4ax22-nlc-1269\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'classes': [{u'class_name': u'0', u'confidence': 0.9695191215271693},\n",
       "  {u'class_name': u'4', u'confidence': 0.030480878472830677}],\n",
       " u'classifier_id': u'c7fa4ax22-nlc-1270',\n",
       " u'text': u'@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
       " u'top_class': u'0',\n",
       " u'url': u'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/c7fa4ax22-nlc-1270'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5000\n",
    "classd_dict[\"c7fa4ax22-nlc-1270\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  c7fa4ax22-nlc-1269\n",
      "Accuracy:  0.701949860724\n",
      "Confidence:  [0.8783337808603239, 0.94176920671881]\n",
      "Classifier:  c7fa4ax22-nlc-1270\n",
      "Accuracy:  0.701949860724\n",
      "Confidence:  [0.8598635146732335, 0.9264322311912503]\n",
      "Classifier:  c7fa49x23-nlc-1182\n",
      "Accuracy:  0.66573816156\n",
      "Confidence:  [0.8672577321084317, 0.9157234826881114]\n"
     ]
    }
   ],
   "source": [
    "#STEP 3: Compute the accuracy for each classifier\n",
    "#STEP 4: Compute the confidence of each class for each classifier\n",
    "\n",
    "per_classifier_acc = []\n",
    "per_classifier_confidence = [] # pairs per classifier (one for each class)\n",
    "for c_id in get_classifier_ids(username, password):\n",
    "    per_classifier_list = classd_dict[c_id]\n",
    "    \n",
    "    print \"Classifier: \", c_id\n",
    "\n",
    "    try:\n",
    "        acc = compute_accuracy_of_single_classifier(per_classifier_list, input_test_data)\n",
    "    except Exception as e:\n",
    "        print \"Error: {}\".format(e)\n",
    "    else:\n",
    "        per_classifier_acc.append(acc)\n",
    "        print \"Accuracy: \", acc\n",
    "\n",
    "    try:\n",
    "        conf = compute_average_confidence_of_single_classifier(per_classifier_list, input_test_data)\n",
    "    except Exception as e:\n",
    "        print \"Error: {}\".format(e)\n",
    "    else:\n",
    "        per_classifier_confidence.append(conf)\n",
    "        print \"Confidence: \", conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'c7fa4ax22-nlc-1269', u'c7fa4ax22-nlc-1270', u'c7fa49x23-nlc-1182']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2500, 5000, 500\n",
    "get_classifier_ids(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7019498607242339, 0.7019498607242339, 0.6657381615598886]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_classifier_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8783337808603239, 0.94176920671881],\n",
       " [0.8598635146732335, 0.9264322311912503],\n",
       " [0.8672577321084317, 0.9157234826881114]]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrect, correct\n",
    "per_classifier_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2500 = classd_dict['c7fa4ax22-nlc-1269']\n",
    "c5000 = classd_dict['c7fa4ax22-nlc-1270']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 4 0 0 0 0\n",
      "True 4 4 4 1 1\n",
      "True 4 4 4 2 2\n",
      "True 4 0 0 2 2\n",
      "True 4 0 0 2 2\n",
      "True 4 4 4 3 3\n",
      "True 0 0 4 4 3\n",
      "True 4 4 4 5 4\n",
      "True 4 4 4 6 5\n",
      "True 4 4 4 7 6\n",
      "True 0 0 0 8 7\n",
      "True 4 0 4 8 8\n",
      "True 4 4 4 9 9\n",
      "True 0 0 4 10 9\n",
      "True 4 0 0 10 9\n",
      "True 0 0 4 11 9\n",
      "True 4 4 4 12 10\n",
      "True 0 0 0 13 11\n",
      "True 4 0 0 13 11\n",
      "True 4 4 4 14 12\n",
      "True 4 4 4 15 13\n",
      "True 4 4 0 16 13\n",
      "True 4 4 4 17 14\n",
      "True 4 0 4 17 15\n",
      "True 4 4 4 18 16\n",
      "True 4 0 4 18 17\n",
      "True 4 4 4 19 18\n",
      "True 4 4 4 20 19\n",
      "True 4 4 4 21 20\n",
      "True 4 4 4 22 21\n",
      "True 0 4 0 22 22\n",
      "True 0 4 4 22 22\n",
      "True 0 0 4 23 22\n",
      "True 0 0 0 24 23\n",
      "True 0 0 0 25 24\n",
      "True 4 4 4 26 25\n",
      "True 4 4 0 27 25\n",
      "True 4 4 4 28 26\n",
      "True 4 4 4 29 27\n",
      "True 0 0 0 30 28\n",
      "True 0 0 0 31 29\n",
      "True 0 4 4 31 29\n",
      "True 0 4 4 31 29\n",
      "True 0 0 0 32 30\n",
      "True 0 4 4 32 30\n",
      "True 4 0 4 32 31\n",
      "True 0 4 4 32 31\n",
      "True 4 4 4 33 32\n",
      "True 4 4 4 34 33\n",
      "True 4 4 0 35 33\n",
      "True 0 0 0 36 34\n",
      "True 4 4 4 37 35\n",
      "True 4 4 4 38 36\n",
      "True 0 0 4 39 36\n",
      "True 0 0 0 40 37\n",
      "True 4 4 4 41 38\n",
      "True 4 4 4 42 39\n",
      "True 4 4 4 43 40\n",
      "True 0 0 0 44 41\n",
      "True 4 0 0 44 41\n",
      "True 4 4 4 45 42\n",
      "True 4 4 0 46 42\n",
      "True 0 4 0 46 43\n",
      "True 0 0 4 47 43\n",
      "True 4 4 4 48 44\n",
      "True 0 0 0 49 45\n",
      "True 4 4 4 50 46\n",
      "True 4 4 4 51 47\n",
      "True 0 4 0 51 48\n",
      "True 0 0 0 52 49\n",
      "True 0 0 0 53 50\n",
      "True 0 0 0 54 51\n",
      "True 0 0 4 55 51\n",
      "True 0 0 0 56 52\n",
      "True 0 0 0 57 53\n",
      "True 0 0 0 58 54\n",
      "True 0 0 0 59 55\n",
      "True 4 0 0 59 55\n",
      "True 0 0 0 60 56\n",
      "True 0 0 0 61 57\n",
      "True 0 0 0 62 58\n",
      "True 0 0 0 63 59\n",
      "True 0 4 4 63 59\n",
      "True 0 4 4 63 59\n",
      "True 0 4 4 63 59\n",
      "True 0 0 0 64 60\n",
      "True 0 0 0 65 61\n",
      "True 0 4 4 65 61\n",
      "True 4 4 4 66 62\n",
      "True 4 4 4 67 63\n",
      "True 4 4 4 68 64\n",
      "True 4 4 4 69 65\n",
      "True 4 4 4 70 66\n",
      "True 4 4 4 71 67\n",
      "True 4 0 4 71 68\n",
      "True 4 4 4 72 69\n",
      "True 4 4 4 73 70\n",
      "True 4 0 4 73 71\n",
      "True 4 4 4 74 72\n",
      "True 4 4 4 75 73\n",
      "True 4 4 4 76 74\n",
      "True 0 0 0 77 75\n",
      "True 4 0 4 77 76\n",
      "True 4 4 4 78 77\n",
      "True 4 4 4 79 78\n",
      "True 4 4 4 80 79\n",
      "True 4 0 0 80 79\n",
      "True 4 4 4 81 80\n",
      "True 4 4 4 82 81\n",
      "True 0 0 4 83 81\n",
      "True 0 0 0 84 82\n",
      "True 0 4 4 84 82\n",
      "True 0 4 4 84 82\n",
      "True 0 0 0 85 83\n",
      "True 0 0 4 86 83\n",
      "True 0 4 0 86 84\n",
      "True 0 0 0 87 85\n",
      "True 0 0 0 88 86\n",
      "True 0 4 4 88 86\n",
      "True 0 0 0 89 87\n",
      "True 0 0 0 90 88\n",
      "True 0 0 0 91 89\n",
      "True 0 4 4 91 89\n",
      "True 0 0 0 92 90\n",
      "True 0 0 0 93 91\n",
      "True 0 0 0 94 92\n",
      "True 0 0 0 95 93\n",
      "True 4 0 0 95 93\n",
      "True 0 0 0 96 94\n",
      "True 0 0 4 97 94\n",
      "True 4 0 0 97 94\n",
      "True 0 0 0 98 95\n",
      "True 0 0 0 99 96\n",
      "True 0 0 0 100 97\n",
      "True 0 0 0 101 98\n",
      "True 4 4 4 102 99\n",
      "True 0 4 4 102 99\n",
      "True 0 0 4 103 99\n",
      "True 4 0 0 103 99\n",
      "True 0 4 4 103 99\n",
      "True 4 4 4 104 100\n",
      "True 4 0 4 104 101\n",
      "True 4 4 4 105 102\n",
      "True 4 4 4 106 103\n",
      "True 4 0 0 106 103\n",
      "True 4 4 4 107 104\n",
      "True 4 4 4 108 105\n",
      "True 0 0 0 109 106\n",
      "True 0 0 0 110 107\n",
      "True 0 0 0 111 108\n",
      "True 0 0 0 112 109\n",
      "True 0 0 0 113 110\n",
      "True 0 0 4 114 110\n",
      "True 0 0 4 115 110\n",
      "True 4 0 0 115 110\n",
      "True 0 4 4 115 110\n",
      "True 0 0 0 116 111\n",
      "True 0 0 0 117 112\n",
      "True 0 0 4 118 112\n",
      "True 0 0 0 119 113\n",
      "True 0 4 4 119 113\n",
      "True 0 0 0 120 114\n",
      "True 0 0 4 121 114\n",
      "True 0 0 0 122 115\n",
      "True 0 0 0 123 116\n",
      "True 0 4 4 123 116\n",
      "True 0 4 4 123 116\n",
      "True 0 4 4 123 116\n",
      "True 4 4 4 124 117\n",
      "True 4 4 4 125 118\n",
      "True 4 4 4 126 119\n",
      "True 4 4 4 127 120\n",
      "True 0 4 4 127 120\n",
      "True 4 4 4 128 121\n",
      "True 4 4 4 129 122\n",
      "True 4 4 4 130 123\n",
      "True 4 4 4 131 124\n",
      "True 4 0 4 131 125\n",
      "True 4 4 4 132 126\n",
      "True 4 4 4 133 127\n",
      "True 0 4 0 133 128\n",
      "True 4 0 0 133 128\n",
      "True 4 0 4 133 129\n",
      "True 4 4 4 134 130\n",
      "True 4 4 0 135 130\n",
      "True 4 0 0 135 130\n",
      "True 4 0 0 135 130\n",
      "True 4 0 4 135 131\n",
      "True 4 0 4 135 132\n",
      "True 0 0 0 136 133\n",
      "True 4 0 4 136 134\n",
      "True 4 4 4 137 135\n",
      "True 0 0 0 138 136\n",
      "True 4 0 4 138 137\n",
      "True 4 4 4 139 138\n",
      "True 4 4 4 140 139\n",
      "True 4 4 4 141 140\n",
      "True 4 0 4 141 141\n",
      "True 4 4 4 142 142\n",
      "True 0 4 0 142 143\n",
      "True 0 0 0 143 144\n",
      "True 4 4 4 144 145\n",
      "True 4 4 0 145 145\n",
      "True 4 0 4 145 146\n",
      "True 4 4 0 146 146\n",
      "True 4 4 4 147 147\n",
      "True 4 4 4 148 148\n",
      "True 0 0 0 149 149\n",
      "True 0 0 0 150 150\n",
      "True 0 0 0 151 151\n",
      "True 4 4 4 152 152\n",
      "True 0 4 4 152 152\n",
      "True 4 0 4 152 153\n",
      "True 4 4 4 153 154\n",
      "True 4 4 4 154 155\n",
      "True 4 4 4 155 156\n",
      "True 4 4 4 156 157\n",
      "True 0 0 4 157 157\n",
      "True 0 4 4 157 157\n",
      "True 4 4 4 158 158\n",
      "True 4 0 0 158 158\n",
      "True 0 0 0 159 159\n",
      "True 0 0 0 160 160\n",
      "True 0 0 0 161 161\n",
      "True 0 0 0 162 162\n",
      "True 0 4 4 162 162\n",
      "True 0 4 4 162 162\n",
      "True 0 4 4 162 162\n",
      "True 4 4 4 163 163\n",
      "True 0 0 4 164 163\n",
      "True 4 0 0 164 163\n",
      "True 4 0 4 164 164\n",
      "True 0 4 0 164 165\n",
      "True 4 4 4 165 166\n",
      "True 0 0 0 166 167\n",
      "True 4 4 4 167 168\n",
      "True 4 0 4 167 169\n",
      "True 4 4 4 168 170\n",
      "True 4 4 4 169 171\n",
      "True 4 0 4 169 172\n",
      "True 4 0 0 169 172\n",
      "True 4 4 4 170 173\n",
      "True 4 0 4 170 174\n",
      "True 4 4 4 171 175\n",
      "True 4 0 0 171 175\n",
      "True 0 4 0 171 176\n",
      "True 0 4 4 171 176\n",
      "True 0 4 0 171 177\n",
      "True 0 4 4 171 177\n",
      "True 0 0 0 172 178\n",
      "True 0 0 0 173 179\n",
      "True 0 0 0 174 180\n",
      "True 4 4 4 175 181\n",
      "True 0 0 0 176 182\n",
      "True 4 4 4 177 183\n",
      "True 4 4 0 178 183\n",
      "True 4 4 4 179 184\n",
      "True 4 0 0 179 184\n",
      "True 4 0 4 179 185\n",
      "True 4 4 4 180 186\n",
      "True 0 0 0 181 187\n",
      "True 0 0 4 182 187\n",
      "True 0 0 0 183 188\n",
      "True 4 4 4 184 189\n",
      "True 4 4 4 185 190\n",
      "True 4 4 4 186 191\n",
      "True 4 0 0 186 191\n",
      "True 4 4 4 187 192\n",
      "True 4 4 4 188 193\n",
      "True 4 4 4 189 194\n",
      "True 4 4 4 190 195\n",
      "True 4 4 4 191 196\n",
      "True 4 4 4 192 197\n",
      "True 4 0 4 192 198\n",
      "True 4 4 4 193 199\n",
      "True 0 0 0 194 200\n",
      "True 4 4 0 195 200\n",
      "True 4 0 0 195 200\n",
      "True 0 4 4 195 200\n",
      "True 4 4 4 196 201\n",
      "True 4 4 4 197 202\n",
      "True 4 4 0 198 202\n",
      "True 0 0 0 199 203\n",
      "True 0 0 0 200 204\n",
      "True 0 0 0 201 205\n",
      "True 0 4 4 201 205\n",
      "True 0 4 0 201 206\n",
      "True 0 4 4 201 206\n",
      "True 0 4 4 201 206\n",
      "True 0 0 4 202 206\n",
      "True 0 4 4 202 206\n",
      "True 0 0 0 203 207\n",
      "True 0 0 0 204 208\n",
      "True 0 0 0 205 209\n",
      "True 0 0 4 206 209\n",
      "True 0 0 4 207 209\n",
      "True 0 0 4 208 209\n",
      "True 0 4 0 208 210\n",
      "True 0 0 0 209 211\n",
      "True 0 0 0 210 212\n",
      "True 0 4 4 210 212\n",
      "True 0 0 0 211 213\n",
      "True 0 4 4 211 213\n",
      "True 0 4 4 211 213\n",
      "True 0 0 0 212 214\n",
      "True 0 0 4 213 214\n",
      "True 0 0 0 214 215\n",
      "True 0 4 4 214 215\n",
      "True 4 0 0 214 215\n",
      "True 4 0 0 214 215\n",
      "True 0 0 0 215 216\n",
      "True 0 0 0 216 217\n",
      "True 0 0 0 217 218\n",
      "True 0 0 0 218 219\n",
      "True 4 4 4 219 220\n",
      "True 0 0 0 220 221\n",
      "True 0 0 4 221 221\n",
      "True 4 4 4 222 222\n",
      "True 4 4 0 223 222\n",
      "True 4 4 4 224 223\n",
      "True 0 0 0 225 224\n",
      "True 4 4 0 226 224\n",
      "True 4 4 4 227 225\n",
      "True 4 4 4 228 226\n",
      "True 4 4 4 229 227\n",
      "True 0 0 0 230 228\n",
      "True 4 0 0 230 228\n",
      "True 0 0 0 231 229\n",
      "True 4 0 4 231 230\n",
      "True 0 4 4 231 230\n",
      "True 0 0 0 232 231\n",
      "True 0 4 4 232 231\n",
      "True 0 4 4 232 231\n",
      "True 4 4 4 233 232\n",
      "True 0 0 0 234 233\n",
      "True 4 4 4 235 234\n",
      "True 0 4 0 235 235\n",
      "True 4 4 4 236 236\n",
      "True 4 0 0 236 236\n",
      "True 4 4 4 237 237\n",
      "True 0 0 0 238 238\n",
      "True 4 4 4 239 239\n",
      "True 4 4 0 240 239\n",
      "True 4 4 4 241 240\n",
      "True 4 0 4 241 241\n",
      "True 0 0 0 242 242\n",
      "True 0 0 4 243 242\n",
      "True 0 0 0 244 243\n",
      "True 0 0 0 245 244\n",
      "True 0 4 4 245 244\n",
      "True 4 4 4 246 245\n",
      "True 4 4 4 247 246\n",
      "True 0 4 4 247 246\n",
      "True 4 4 4 248 247\n",
      "True 4 0 4 248 248\n",
      "True 0 0 0 249 249\n",
      "True 4 4 4 250 250\n",
      "True 0 0 0 251 251\n",
      "True 0 0 0 252 252\n"
     ]
    }
   ],
   "source": [
    "c25_count = 0\n",
    "c50_count = 0\n",
    "with open('datasets/testdata.manualSUBSET.2009.06.14.csv', \"r\") as _input:\n",
    "    reader = csv.reader(_input)\n",
    "    for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "        c25_count += int(row[0]) == int(c2500[i][\"top_class\"])\n",
    "        c50_count += int(row[0]) == int(c5000[i][\"top_class\"])\n",
    "        print row[-1] == c5000[i]['text'], row[0], c2500[i][\"top_class\"], c5000[i][\"top_class\"], c25_count, c50_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.594109010793\n",
      "True 0.833372883793\n",
      "True 0.994297037853\n",
      "False 0.925776787261\n",
      "False 0.761682483917\n",
      "True 0.964038764622\n",
      "True 0.675257328087\n",
      "True 0.994124253741\n",
      "True 0.957353384661\n",
      "True 0.994521193364\n",
      "True 0.861516535924\n",
      "False 0.782268259084\n",
      "True 0.995863140786\n",
      "True 0.631433517035\n",
      "False 0.609723912169\n",
      "True 0.986952520095\n",
      "True 0.974833775911\n",
      "True 0.962148141958\n",
      "False 0.879201303981\n",
      "True 0.962473580512\n",
      "True 0.978490771472\n",
      "True 0.789603688858\n",
      "True 0.975537957902\n",
      "False 0.995356939368\n",
      "True 0.995692838113\n",
      "False 0.969377728616\n",
      "True 0.911339422317\n",
      "True 0.826478933656\n",
      "True 0.974684945777\n",
      "True 0.954754465685\n",
      "False 0.949260967649\n",
      "False 0.973851763333\n",
      "True 0.996336492761\n",
      "True 0.993791642773\n",
      "True 0.707637073163\n",
      "True 0.9710868746\n",
      "True 0.990851804916\n",
      "True 0.96842419971\n",
      "True 0.741974467497\n",
      "True 0.995890526921\n",
      "True 0.995673578881\n",
      "False 0.972642985095\n",
      "False 0.604265443469\n",
      "True 0.702149115612\n",
      "False 0.833599665794\n",
      "False 0.967926334309\n",
      "False 0.950811428738\n",
      "True 0.973141113436\n",
      "True 0.977797724388\n",
      "True 0.807114664847\n",
      "True 0.968036367128\n",
      "True 0.996200905716\n",
      "True 0.990353601421\n",
      "True 0.854742746926\n",
      "True 0.624463103207\n",
      "True 0.849363442114\n",
      "True 0.608755402963\n",
      "True 0.976312360018\n",
      "True 0.959697226064\n",
      "False 0.64992113132\n",
      "True 0.974884832898\n",
      "True 0.964186964887\n",
      "False 0.769311527753\n",
      "True 0.949605745611\n",
      "True 0.956570576909\n",
      "True 0.993938629154\n",
      "True 0.976752427204\n",
      "True 0.993774763736\n",
      "False 0.964688657347\n",
      "True 0.957204240291\n",
      "True 0.710187619412\n",
      "True 0.995704779851\n",
      "True 0.610597313962\n",
      "True 0.969877844834\n",
      "True 0.995372851984\n",
      "True 0.994744821229\n",
      "True 0.996798520513\n",
      "False 0.962752089079\n",
      "True 0.972582760653\n",
      "True 0.996283286482\n",
      "True 0.995710140705\n",
      "True 0.994452966735\n",
      "False 0.968172917341\n",
      "False 0.994008474258\n",
      "False 0.995499109391\n",
      "True 0.971428761969\n",
      "True 0.873054828441\n",
      "False 0.605936593028\n",
      "True 0.994885396903\n",
      "True 0.995041551225\n",
      "True 0.995698896961\n",
      "True 0.996109658637\n",
      "True 0.98105440383\n",
      "True 0.994635791287\n",
      "False 0.951750619295\n",
      "True 0.995073179566\n",
      "True 0.805285372398\n",
      "False 0.819838348011\n",
      "True 0.977801918731\n",
      "True 0.995501550447\n",
      "True 0.994294168076\n",
      "True 0.888537159889\n",
      "False 0.938629432711\n",
      "True 0.962236907759\n",
      "True 0.971392787663\n",
      "True 0.968945784306\n",
      "False 0.9733205938\n",
      "True 0.97961548667\n",
      "True 0.995087218346\n",
      "True 0.934228786849\n",
      "True 0.99457246028\n",
      "False 0.993327183515\n",
      "False 0.563511804453\n",
      "True 0.994271273461\n",
      "True 0.974718727262\n",
      "False 0.710675102587\n",
      "True 0.795046845262\n",
      "True 0.856073930421\n",
      "False 0.528007197259\n",
      "True 0.994068039924\n",
      "True 0.980787180403\n",
      "True 0.982094977044\n",
      "False 0.972817877394\n",
      "True 0.823428350874\n",
      "True 0.995922863464\n",
      "True 0.993703986038\n",
      "True 0.9694985226\n",
      "False 0.996042936635\n",
      "True 0.996969798352\n",
      "True 0.77169381784\n",
      "False 0.994294761408\n",
      "True 0.995365085183\n",
      "True 0.994008114007\n",
      "True 0.615847228558\n",
      "True 0.993716064264\n",
      "True 0.964771025348\n",
      "False 0.964935467252\n",
      "True 0.701993862178\n",
      "False 0.865734664584\n",
      "False 0.964734983112\n",
      "True 0.963684647806\n",
      "False 0.803063163783\n",
      "True 0.992931863956\n",
      "True 0.994377946297\n",
      "False 0.994498848696\n",
      "True 0.972861860966\n",
      "True 0.979886055342\n",
      "True 0.989490736854\n",
      "True 0.995180390215\n",
      "True 0.949005172933\n",
      "True 0.991845307083\n",
      "True 0.775231751267\n",
      "True 0.734982857059\n",
      "True 0.959655562586\n",
      "False 0.994869188062\n",
      "False 0.576051740782\n",
      "True 0.993081448448\n",
      "True 0.969878157126\n",
      "True 0.965270260204\n",
      "True 0.995702132294\n",
      "False 0.979162217562\n",
      "True 0.970236409368\n",
      "True 0.994092598485\n",
      "True 0.994402951726\n",
      "True 0.838610581074\n",
      "False 0.995734866105\n",
      "False 0.980144978445\n",
      "False 0.706976990803\n",
      "True 0.980699812475\n",
      "True 0.972426360582\n",
      "True 0.856442932189\n",
      "True 0.980837052544\n",
      "False 0.994851943511\n",
      "True 0.995546093168\n",
      "True 0.996652876261\n",
      "True 0.99640134401\n",
      "True 0.995709435306\n",
      "False 0.827928446632\n",
      "True 0.994259911151\n",
      "True 0.938363791513\n",
      "False 0.776754334591\n",
      "False 0.962916209813\n",
      "False 0.984187321194\n",
      "True 0.956017068106\n",
      "True 0.804004075948\n",
      "False 0.992198854297\n",
      "False 0.853108214704\n",
      "False 0.572414551447\n",
      "False 0.994285081156\n",
      "True 0.992765585509\n",
      "False 0.8813336729\n",
      "True 0.957954460031\n",
      "True 0.992176443496\n",
      "False 0.775603973355\n",
      "True 0.963697968484\n",
      "True 0.979995080911\n",
      "True 0.994502112599\n",
      "False 0.97249390365\n",
      "True 0.970738774195\n",
      "False 0.993989966089\n",
      "True 0.994807362534\n",
      "True 0.99571128735\n",
      "True 0.97544484498\n",
      "False 0.96680160192\n",
      "True 0.982026724676\n",
      "True 0.996782975617\n",
      "True 0.995638743136\n",
      "True 0.994622940876\n",
      "True 0.991640941854\n",
      "True 0.972154102822\n",
      "True 0.971422424131\n",
      "False 0.921899746371\n",
      "False 0.983193414792\n",
      "True 0.86202647679\n",
      "True 0.974866339183\n",
      "True 0.995022758833\n",
      "True 0.951594092509\n",
      "True 0.967814384926\n",
      "False 0.994453448907\n",
      "True 0.97704323714\n",
      "False 0.993146482253\n",
      "True 0.995634411757\n",
      "True 0.995083195863\n",
      "True 0.966631256708\n",
      "True 0.993958549539\n",
      "False 0.626709253771\n",
      "False 0.668806812715\n",
      "False 0.958494018197\n",
      "True 0.976710870108\n",
      "True 0.955796697978\n",
      "False 0.966633010567\n",
      "False 0.95406208186\n",
      "False 0.956236211997\n",
      "True 0.996084044278\n",
      "True 0.995125658456\n",
      "True 0.971630242875\n",
      "False 0.967936143281\n",
      "True 0.978825100682\n",
      "True 0.960467807034\n",
      "False 0.947706271776\n",
      "False 0.505455319435\n",
      "True 0.996160495158\n",
      "False 0.96863719824\n",
      "True 0.874022607036\n",
      "False 0.584609300255\n",
      "False 0.993625456162\n",
      "False 0.979499480255\n",
      "False 0.977900667311\n",
      "False 0.945421515809\n",
      "True 0.994393374252\n",
      "True 0.968994872117\n",
      "True 0.996240091989\n",
      "True 0.975447151679\n",
      "True 0.668674490137\n",
      "True 0.995450021463\n",
      "True 0.993588396591\n",
      "True 0.602320537702\n",
      "False 0.966574508141\n",
      "False 0.538140469439\n",
      "True 0.76441840327\n",
      "True 0.968540528546\n",
      "True 0.945939421196\n",
      "True 0.773771444108\n",
      "True 0.994190105523\n",
      "True 0.996338728185\n",
      "True 0.995472121453\n",
      "False 0.835705248225\n",
      "True 0.982546507718\n",
      "True 0.996326228427\n",
      "True 0.995339439056\n",
      "True 0.892580586246\n",
      "True 0.994988338117\n",
      "True 0.98269700823\n",
      "False 0.965735507142\n",
      "True 0.995880531837\n",
      "True 0.943275355029\n",
      "True 0.961432741585\n",
      "False 0.804901726856\n",
      "False 0.793157608059\n",
      "True 0.793214353053\n",
      "True 0.970180925421\n",
      "True 0.845611340556\n",
      "True 0.80582841034\n",
      "True 0.576113665739\n",
      "True 0.995019452974\n",
      "False 0.987937230536\n",
      "False 0.970232349546\n",
      "False 0.936267939417\n",
      "False 0.994266219986\n",
      "True 0.920356175264\n",
      "False 0.963068853709\n",
      "True 0.994495623591\n",
      "True 0.995020081793\n",
      "True 0.995826138498\n",
      "True 0.962894519683\n",
      "True 0.703249561162\n",
      "True 0.95830736519\n",
      "False 0.748313836878\n",
      "True 0.995896593812\n",
      "True 0.994291257881\n",
      "False 0.610446814148\n",
      "True 0.9955452263\n",
      "False 0.646033021661\n",
      "False 0.834278998774\n",
      "True 0.996187768719\n",
      "True 0.977724234816\n",
      "True 0.981105778103\n",
      "False 0.842353466941\n",
      "False 0.993056391566\n",
      "False 0.590244084998\n",
      "True 0.995158477442\n",
      "True 0.994285739882\n",
      "True 0.995488679011\n",
      "True 0.996127621421\n",
      "True 0.963646459714\n",
      "True 0.658498109223\n",
      "True 0.97057651181\n",
      "True 0.996823731664\n",
      "True 0.993426192672\n",
      "True 0.970833775083\n",
      "True 0.971428015562\n",
      "True 0.698099995807\n",
      "True 0.971516438998\n",
      "True 0.995005296605\n",
      "True 0.995205882982\n",
      "True 0.995414775197\n",
      "False 0.96140927936\n",
      "True 0.974805750294\n",
      "False 0.946945535549\n",
      "False 0.97122950208\n",
      "True 0.960047519222\n",
      "False 0.953720536171\n",
      "False 0.993476215667\n",
      "True 0.963741677031\n",
      "True 0.969576400625\n",
      "True 0.99658194824\n",
      "False 0.969195052953\n",
      "True 0.958648641365\n",
      "False 0.992462308652\n",
      "True 0.995591134038\n",
      "True 0.947386161822\n",
      "True 0.996739072352\n",
      "True 0.939700491349\n",
      "True 0.98355543247\n",
      "False 0.977907725933\n",
      "True 0.977499908608\n",
      "True 0.989798547378\n",
      "True 0.99653878611\n",
      "True 0.95676417387\n",
      "False 0.972235247854\n",
      "True 0.995694388164\n",
      "True 0.977998168865\n",
      "False 0.965446405073\n",
      "True 0.975584516793\n",
      "False 0.865410078183\n",
      "True 0.964322376663\n",
      "True 0.736427163739\n",
      "True 0.994392594275\n",
      "True 0.98058782809\n"
     ]
    }
   ],
   "source": [
    "c25_conf = 0\n",
    "c50_conf = 0\n",
    "with open('datasets/testdata.manualSUBSET.2009.06.14.csv', \"r\") as _input:\n",
    "    reader = csv.reader(_input)\n",
    "    for i, row in enumerate(itertools.islice(reader, 0, None)):\n",
    "        actual_class = int(row[0])\n",
    "        \n",
    "        class0 = c2500[i][\"classes\"][0][\"class_name\"]\n",
    "        conf0 = c2500[i][\"classes\"][0][\"confidence\"]\n",
    "        \n",
    "        class1 = c2500[i][\"classes\"][1][\"class_name\"]\n",
    "        conf1 = c2500[i][\"classes\"][1][\"confidence\"]\n",
    "\n",
    "        #selected_index = next(index for (index, d) in enumerate(conf_list) if d[\"class_name\"] == top_class)\n",
    "        #confidence_sums[tweet_class / 4] += conf_list[selected_index][\"confidence\"]\n",
    "        \n",
    "        print actual_class == int(class0), conf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
